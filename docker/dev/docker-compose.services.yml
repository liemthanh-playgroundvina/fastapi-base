version: '3.8'

services:
  # LLM
  llm:
    image: ${DOCKER_HUB_URL}/${NAME}-llm:${ENV}
    container_name: ${NAME}-${ENV}-llm
    command: [ "/app/scripts/entrypoint.sh" ]
    restart: always
    env_file:
      - .env
    expose:
      - 8000
    volumes:
      - volume-llm:/models
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [ gpu ]
    networks:
       - net

  # Embedding Models Interface
  em:
    image: ghcr.io/huggingface/text-embeddings-inference:cuda-1.5
    container_name: ${NAME}-${ENV}-em
    command: ["--port", "8000", "--model-id", "BAAI/bge-m3"]
    restart: always
    env_file:
      - .env
    expose:
      - 8000
    volumes:
      - volume-em:/data
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [ gpu ]
    networks:
      - net

  # Vectordb
  vdb:
    image: ghcr.io/qdrant/qdrant/qdrant:v1.11.1-unprivileged
    container_name: ${NAME}-${ENV}-vdb
    restart: always
    env_file:
      - .env
    expose:
      - 6333
    volumes:
      - volume-vdb:/qdrant/storage
    networks:
      - net

volumes:
  volume-llm:
    name: ${NAME}-${ENV}-llm-data
  volume-em:
    name: ${NAME}-${ENV}-em-data
  volume-vdb:
    name: ${NAME}-${ENV}-vdb-data

networks:
  net:
    name: ${NAME}-${ENV}-net